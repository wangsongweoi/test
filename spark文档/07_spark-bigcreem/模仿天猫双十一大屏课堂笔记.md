# **可视化大屏课堂讲义**

# **1.** **背景&目的**

Ø 参考网站

https://ark.analysys.cn/portal/industry-demo.html

https://tongji.baidu.com/web/welcome/login

https://www.umeng.com/?spm=a211g2.11755511.0.0.117d19e9EpW1I7

 

l 案例一：

构建数据仓库，建设覆盖财务、采购、人力、猪/禽/鲜品/熟食零售等各产业全流程的经营分析体系，提供数据监控、预警和决策支持。

通过实时大屏、管理看板和固定报表等不同数据消费形式，满足从集团总裁到部门经理、业务线人员等各层级的日常经营管理数据分析需求，轻松掌握企业经营状况。

l 案例二:

通过构建数据仓库，建设覆盖各个产品线、店铺、品牌、物流、采购、支付等等泉流的经营分析体系，提供数据监控、预警和决策支持。

通过可视化实时大屏和固定报表等不同数据的消费形式，满足本企业不同级别人员的对各个业务线、部门日常经营管理数据分析需求，轻松掌握企业经营状况。

总体把握，第一公司领导决策层希望能能够更快，更准确的把握公司各个层面的运营数据情况；第二方便配合公司进行商务活动，丰富公司发言人的一些数据依据等待。

# **2.** **企业级的项目开发流程**

项目：广义上说包含：产品+项目；狭义上说就是项目。

A. 项目立项

参与投标(外部进行投标，有可能也是在内部部分或者分公司之间进行投标)，公司内部产品开发。

项目就要成立。

B. 需求分析调研

直接到客户现场去和客户进行交流，询问客户有哪些需求，为了更加准确的记录客户的需求，可以通过视频，音频、图像、文字记录等待一系列方式记录需求。回来之后，就需要将这各个方面转化为书面的表达，最后形成需求说明文档。说白了需求说明文档，就是该项目的大体的设计。

C. 概要设计

概要设计主要就是对需求说明文档的理解，细化。

比如，相关模块的数据库如何设计，表有哪些字段、表与表之间的关联关系是怎样，核心模块使用怎样的算法来完成。

D. 详细设计

详细设计便是对概要设计的补充和具体化。涉及到各个模块之间的工作流程，各个模块间的关联系如何等待。

E. 编码阶段

完成自己所负责的各个单元模块的开发工作，一般公司都是对详细设计和编码开发工作是交叉进行。加班。

F. 进行测试阶段

单元测试和项目联调。

单元测试就是自己负责自己开发的单元模块，通过代码测试来完成；项目组进行联调一般都是有专业的测试工程师进行测试。

以测试报告的方式进行呈现。将通过或者未通过的模块列表罗列出来，供各位程序员同事进行进行任务认领——buglist。

![img](assets\wps1.jpg) 

G. 项目上线

项目上线，必须要有严格的上线流程，部署说明流程，如果项目是交付给客户的，那么则必须要编写项目安装部署文档。

H. 线上运维

和各种各样的在测试中没有出现的bug进行打交道的过程，持续时间很长很长。

# **3.** **项目需求**

![img](assets\wps2.jpg) 

基本的项目实现功能：

## **3.1.** **商品交易额实时统计**

![img](assets\wps3.jpg) 

## **3.2.** **商品销售额排行榜**

![img](assets\wps4.jpg) 

## **3.3.** **最受欢迎商品排行榜**

![img](assets\wps5.jpg) 

## **3.4.** **实时商品成交额统计分析**

![img](assets\wps6.jpg) 

## **3.5.** **实时商品成交量统计分析**

![img](assets\wps7.jpg) 

## **3.6.** **消费人群统计**

![img](assets\wps8.jpg) 

## **3.7.** **消费区域统计**

![img](assets\wps9.jpg) 

## **3.8.** **无线pc端流量，成交占比**

## **3.9.** **各品类各品牌成交额、成交量排行**

分组排序TopN

# **4.** **项目系统架构**

![img](assets\wps10.jpg) 

# **5.** **项目数据流程**

![img](assets\wps11.jpg) 

 

# **6.** **项目基础数据准备**

## **6.1.** **服务列表**

![img](assets\wps12.jpg) 

## **6.2.** **基本数据**

![img](assets\wps13.jpg) 

## **6.3.** **数据结构**

![img](assets\wps14.jpg) 

![img](assets\wps15.jpg) 

## **6.4.** **项目开发使用的软件**

**SpringBoot**

**Spark**

**Maven**

**HDFS**

**Redis**

**Flume**

**Kafka**

**MySQL**

**Echarts**

**Yarn**

**CDH**

**需要大家注意的是：软件版本切不可使用最新版本。**

# **7.** **编码过程**

## **7.1.** **项目工程的构建**

SpringBoot+Maven+MySQL+HBase+Kafka+Flume+Spark+Redis等等。

项目构建使用maven的来进行管理，是maven的模块化开发。

使用Scala进行spark作业的计算，使用SpringBoot进行前端界面管理。

### **7.1.1.** **Idea创建SpringBoot项目**

![img](assets\wps16.jpg) 

![img](assets\wps17.jpg) 

![img](assets\wps18.jpg) 

![img](assets\wps19.jpg) 

![img](assets\wps20.jpg) 

### **7.1.2.** **本可视化的项目工程**

通用模块---Common

计算模块---calc

展示模块---springboot+js

====>maven的继承和聚合

### **7.1.3.** **项目依赖**

- 父模块依赖

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.desheng.bigdata</groupId>
    <artifactId>bigscreen-parent</artifactId>
    <packaging>pom</packaging>
    <version>1.0-SNAPSHOT</version>
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>2.1.4.RELEASE</version>
        <relativePath/>
    </parent>
    <modules>
        <module>bigscreen-common</module>
        <module>bigscreen-calc</module>
        <module>bigscreen-web</module>
    </modules>
    <properties>
        <spark.version>2.2.2</spark.version>
    </properties>
    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-starter-web</artifactId>
            </dependency>
            <dependency>
                <groupId>org.projectlombok</groupId>
                <artifactId>lombok</artifactId>
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-streaming_2.11</artifactId>
                <version>${spark.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-streaming-kafka-0-10_2.11</artifactId>
                <version>${spark.version}</version>
            </dependency>
            <dependency>
                <groupId>redis.clients</groupId>
                <artifactId>jedis</artifactId>
            </dependency>
        </dependencies>
    </dependencyManagement>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>
        </plugins>
    </build>
</project>
```

- Calc模块依赖

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <artifactId>bigscreen-parent</artifactId>
        <groupId>com.desheng.bigdata</groupId>
        <version>1.0-SNAPSHOT</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.desheng.bigdata</groupId>
    <artifactId>bigscreen-calc</artifactId>
    <version>1.0-SNAPSHOT</version>

    <dependencies>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming-kafka-0-10_2.11</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming_2.11</artifactId>
        </dependency>
        <dependency>
            <groupId>com.desheng.bigdata</groupId>
            <artifactId>bigscreen-common</artifactId>
            <version>1.0-SNAPSHOT</version>
        </dependency>
    </dependencies>
</project>
```

- Common模块依赖

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.desheng.bigdata</groupId>
    <artifactId>bigscreen-common</artifactId>
    <version>1.0-SNAPSHOT</version>

    <dependencies>
        <dependency>
            <groupId>redis.clients</groupId>
            <artifactId>jedis</artifactId>
            <version>2.9.0</version>
        </dependency>
    </dependencies>
</project>
```

- Web模块依赖



## **7.2.** **数据采集**

### **7.2.1.** 使用java程序模拟用户点击

​		这里我们使用log4j来模拟用户日志的操作，所以第一步做依赖的导入。

​		常见的java中的日志就是log4j。主要用的日志依赖有：slf4j，还有log4j，log4j2，log4jback。

​		其中slf4j中定义的全是，log4j需要实现的接口，而其它三个都是对slf4j的实现，其中最早的实现为log4j，

因为性能不高，所以就有升级版log4j2，log4jback(性能最高)。

​		但是上述的使用操作几乎都是一样的，得需要依赖log4j的配置文件，有两种形式的配置文件：log4j.properties、log4j.xml。

依赖（parent和common做更新）

```xml
<dependency>
    <groupId>log4j</groupId>
    <artifactId>log4j</artifactId>
    <version>1.2.17</version>
</dependency>
```

#### **7.2.1.1.** **Log4j的配置文件**

```properties
###############################################
# 一下的配置文件都是以log4j.开头
#    一种就是log4j.properties | log4j.xml
# 最最重要就是第一个log4j.rootLogger,指定log4j日志的输出界别(目的地)
# log4j.rootLogger=INFO,stdout,file意思为：
# 日志可以输INFO级别以上的数据，将日志输出到stdout标准控制输出(控制台)，输出到file
#
# 常见的日志输出级别：DEBUG(调试) < INFO(信息) < WARN(警告) < ERROR(错误) < FATAL(致命错误)
#  日志输出的顺序：和日志输出级别一致，即配置为一个级别，输出的内容只能是该级别及其以上级别的信息
#  INFO（输出的包括 INFO WARN ERROR FATAL）
#  ERROR(ERROR FATAL)
#  所以，一般情况下：在开发，测试环境中，日志的级别为DEBUG；在生产环境中，日志级别为INFO
#
#  输出目的地：
#     日志输出的各种各样的目的地，都是通过Appender来进行实现追加的
# 我们在appender中看到的PatternLayout的格式如下：
#
#%m   输出代码中指定的消息
#%n   输出一个回车换行符，Windows平台为“\r\n”，Unix平台为“\n”
#%p   输出优先级，即日志级别：DEBUG，INFO，WARN，ERROR，FATAL
#%r   输出自应用启动到输出该log信息耗费的毫秒数
#%c   输出所属的类目，通常就是所在类的全名
#%t   输出产生该日志事件的线程名
#%d   输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyy MMM dd HH:mm:ss , SSS}，输出类似：2002年10月18日  22 ： 10 ： 28 ， 921
#%l   输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.java: 10 ) log4j配置详解 - stone - stonexmx 的博客
# 常见的Appender
# ConsoleAppender
# FileAppender
#
#
###############################################

##自定义日志的输出级别

log4j.rootLogger=INFO, stdout

##自定义日志
log4j.logger.access=INFO, access

log4j.appender.stdout = org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Target = System.out
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout 
log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} [%t] [%c] [%p] - %m%n

### 输出到日志文件 ###
log4j.appender.R = org.apache.log4j.DailyRollingFileAppender
log4j.appender.R.File = logs/bigscreen.log
log4j.appender.R.Append = true
log4j.appender.R.Threshold = DEBUG
log4j.appender.R.DatePattern = '.'yyyy-MM-dd
log4j.appender.R.layout = org.apache.log4j.PatternLayout
log4j.appender.R.layout.ConversionPattern = %d{yyyy-MM-dd HH:mm:ss} - %m%n

### 业务日志###
log4j.appender.access = org.apache.log4j.DailyRollingFileAppender
log4j.appender.access.File =  logs/bigscreen.access.log
log4j.appender.access.Append = true
log4j.appender.access.Threshold = INFO
log4j.appender.access.layout = org.apache.log4j.PatternLayout
log4j.appender.access.layout.ConversionPattern = %m%n
```

#### **7.2.1.2.** **用户acess日志生成代码**

```java
public class MockLogData {
    private static Logger logger = Logger.getLogger("access");
    public static void main(String[] args) throws Exception {
        if(args == null || args.length < 3) {
            System.err.println("Usage: <inputpath> <start> <size>");
            System.exit(-1);
        }
        String inputpath = args[0];
        LineNumberReader br = new LineNumberReader(new FileReader(inputpath));
        String line = null;
        int start = Integer.valueOf(args[1]);
        int size = Integer.valueOf(args[2]);
        int end = start + size;
        while((line = br.readLine()) != null) {
            int lineNumber = br.getLineNumber();
//            System.out.println(lineNumber);
            if(lineNumber > end) {
                break;
            } else if(lineNumber > start) {
                logger.info(line);
            }
        }
        br.close();
    }
}
```



#### **7.2.1.3.** **打包上传到服务器运行**

需要添加maven打包的插件

```xml
<build>
    <plugins>
        <plugin>
            <artifactId>maven-assembly-plugin</artifactId>
            <configuration>
                <descriptorRefs>
                    <descriptorRef>jar-with-dependencies</descriptorRef>
                </descriptorRefs>
                <archive>
                    <!--<manifest>
                          <mainClass></mainClass>
                        </manifest>-->
                </archive>
            </configuration>
            <executions>
                <execution>
                    <id>make-assembly</id>
                    <phase>package</phase>
                    <goals>
                        <goal>single</goal>
                    </goals>
                </execution>
            </executions>
        </plugin>
    </plugins>
</build>
```

编译打包：

![1565751068972](assets/1565751068972.png) 

运行脚本：

 ```sh
#!/bin/sh

if [ $# -ne 2 ]
then
   echo "Usage: <start> <size>"
   exit -1
fi

java -cp \
bigscreen-common-1.0-SNAPSHOT-jar-with-dependencies.jar \
com.desheng.bigdata.common.mock.MockLogData \
taobao-info.log \
$1 $2
 ```

运行测试：

 ![1565751134565](assets/1565751134565.png)

### **7.2.2.** **通过flume采集用户生成的日志数据**

使用flume采集的配置文件：

```properties
##
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# listening new append data from file
a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /home/bigdata/jars/project/bd-1903/bigscreen/logs/bigscreen.access.log

a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.kafka.bootstrap.servers = bigdata01:9092,bigdata02:9092,bigdata03:9092
a1.sinks.k1.kafka.topic = bigscreen-1903
a1.sinks.k1.kafka.producer.acks = 1
a1.sinks.k1.kafka.producer.linger.ms = 1

# Use a channel which buffers events in memory
a1.channels.c1.type = file
a1.channels.c1.checkpointDir = /home/bigdata/jars/project/bd-1903/bigscreen/check/checkpoint
a1.channels.c1.dataDirs = /home/bigdata/jars/project/bd-1903/bigscreen/check/data
a1.channels.c1.capacity = 100000
a1.channels.c1.transactionCapacity = 10000

# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

### **7.2.3.** **通过kafka进行数据缓存**

#### **7.2.3.1.** **创建topic：**

```sh
kafka-topics.sh --create --topic bigscreen-1903 --zookeeper bigdata01:2181/kafka --partitions 3 --replication-factor 1
```

#### **7.2.3.2.** **Flume和kafka整合测试**

```sh
nohup bin/flume-ng agent -n a1 -c conf -f /home/bigdata/jars/project/bd-1903/bigscreen/flume-kafka-sink-1903.conf >/dev/null 2>&1 &
```

通过kafka消费者监听topic中生成的数据

 ```sh
kafka-console-consumer.sh --topic bigscreen-1903 --bootstrap-server bigdata01:9092,bigdata02:9092,bigdata03:9092 --from-beginning
 ```

## **7.3.** **统计分析**

优秀的补充

查看maven坐标的依赖树使用命令：mvn dependency:tree

![1565754280339](assets/1565754280339.png)

该命令，主要使用排除多个jar冲突是使用。

### **7.3.1.** **SparkStreaming和kafka的整合**

新版本的整合需要指定相关的pom 

> ```
> <dependency>
>     <groupId>org.apache.spark</groupId>
>     <artifactId>spark-streaming-kafka-0-10_2.11</artifactId>
> </dependency>
> ```

程序入口

![1565766095044](assets/1565766095044.png)

#### 7.3.1.1. **本地化策略**

LocationStrategy 新版被API每次都会预先拉取kafka中的数据到缓冲区buffer中。因为相比较于在每个批次中都创建消费者，这种在每一个executor中缓存消费者对于提升作业的性能显得非常重要；为不同的机器中的partitition指定恰当的消费者去拉取数据。这种方式要比之前的api显得比较只能。

大多数情况下，我们选择**PreferConsistent**(优先、偏好一致性)即可。PreferConsistent的特点是，将kafka的分区partition，分发给可用的所有的executor。如果executor(计算)和kafka的分区(数据)都在同一台机器(之间是一一对应的在相关机器上，类似DataNode和NodeManager)，请选择**PreferBrokers**（偏好于节点的策略）。如果在加载数据的时候，会有一些倾斜现象，请选择**PreferFixed。**

在**locationStrategy这种情况下，最多可以缓存64个consumer**。如果想获取更多的缓存的consumer，可以通过配置参数spark.streaming.kafka.consumer.cache.maxCapacity来实现。

#### **7.3.1.2.** **消费者策略**

**ConsumerStrategy**：选择如何在executor和driver上创建，以及配置consumer的相关策略。该接口接收两个泛型参数[K, V],其中K对应的是Kafka Message的Key，V对应的Message的value。

ConsumerStrategy，目前有三个实现的方式：

- Subscribe：就像0.8的版本中提供的订阅某些topic集合即可。

- SubscribePattern：通过对多个topic进行正则匹配来进行订阅。

- Assign：直接进行指派。

### 7.3.2. 指标计算

```scala
package com.desheng.bigscreen.calc.jobs

import com.desheng.bigdata.common.Constants
import com.desheng.bigdata.common.db.JedisUtil
import com.desheng.bigscreen.calc.entity.OrderLog
import org.apache.kafka.clients.consumer.ConsumerRecord
import org.apache.kafka.common.TopicPartition
import org.apache.kafka.common.serialization.StringDeserializer
import org.apache.log4j.{Level, Logger}
import org.apache.spark.SparkConf
import org.apache.spark.rdd.RDD
import org.apache.spark.streaming.dstream.InputDStream
import org.apache.spark.streaming.kafka010._
import org.apache.spark.streaming.{Seconds, StreamingContext}

import scala.collection.JavaConversions._
import scala.collection.mutable
/**
  * 该app完成统计主体内容
  */
object RealTimeBigScreenCalcApp {
    def main(args: Array[String]): Unit = {
        Logger.getLogger("org.apache.spark").setLevel(Level.WARN)
        Logger.getLogger("org.apache.hadoop").setLevel(Level.WARN)
        Logger.getLogger("org.spark_project").setLevel(Level.WARN)
        Logger.getLogger("org.apache.kafka").setLevel(Level.WARN)
        if(args == null || args.length < 1) {
            println(
                """
                  |Parameter Errors! Usage: <batchInterval> <topicStr>
                """.stripMargin)
            System.exit(-1)
        }

        val Array(batchInterval, topicStr) = args

        val conf = new SparkConf()
                .setAppName(s"${RealTimeBigScreenCalcApp.getClass.getSimpleName}")
                .setMaster("local[*]")
        val ssc = new StreamingContext(conf, Seconds(batchInterval.toLong))

        val topics = topicStr.split(",")
        val kafkaParams = Map(
            "bootstrap.servers" -> "bigdata01:9092,bigdata02:9092,bigdata03:9092",
            "key.deserializer" -> classOf[StringDeserializer],
            "value.deserializer" -> classOf[StringDeserializer],
            "group.id" -> "g_bd_1903_4",
            "auto.offset.reset" -> "earliest"
        )
        //kafka整合
        val messages: InputDStream[ConsumerRecord[String, String]] = createMsg(ssc, topics, kafkaParams)
        //计算
        messages.foreachRDD((rdd, bTime) => {
            if(!rdd.isEmpty()) {
                println("-------------------------------------------")
                println(s"Time: $bTime")

                process(rdd)

                println("-------------------------------------------")
                storeOffsets(rdd.asInstanceOf[HasOffsetRanges].offsetRanges, kafkaParams("group.id").toString)
            }
        })
        //落地

        ssc.start()
        ssc.awaitTermination()
    }

    def process(inputRDD: RDD[ConsumerRecord[String, String]]): Unit = {
        val standardRDD:RDD[OrderLog] = inputRDD.map(record => {
            OrderLog.line2OrderLog(record.value())
        }).filter(orderLog => orderLog.time != null)
        standardRDD.persist()
        //实时总交易额
        calcTotalAmt(standardRDD)
        //店铺销售额TopN排行
        calcShopAmtRank(standardRDD)
        //实时交易额变化趋势
        calcRealTimeAmtExtrend(standardRDD)
        //释放持久化数据
        standardRDD.unpersist()
    }

    /**
        如果像前面的两种统计方式，每条记录访问一次redis/hbase db，加入每个批次有10000记录，那就要操作数据1w次
        性能不是很高
        因为这里计算是店铺的销售额，每秒销售额，所以可以通过reduceByKey计算出当前批次的销售额和每秒的销售额，最后
        在将结果更新到数据库，显然操作数据的次数要远低于第一种
      */
    def calcRealTimeAmtExtrend(standardRDD:RDD[OrderLog]):Unit = {
        val time2Amt = standardRDD.map(orderLog => {
            val amt = orderLog.currentPrice * orderLog.sales
            (orderLog.time, amt)
        }).reduceByKey(_+_)

        time2Amt.foreachPartition(partition => {
            val jedis = JedisUtil.getJedis
            partition.foreach{case (time, amt) => {
                jedis.hincrByFloat(Constants.KEY_REAL_TIME_AMT, time, amt)
            }}
            JedisUtil.release(jedis)
        })
    }

    //店铺销售额TopN排行
    def calcShopAmtRank(standardRDD:RDD[OrderLog]): Unit = {
        standardRDD.foreachPartition(partition => {
            val jedis = JedisUtil.getJedis
            partition.foreach(orderLog => {
                val amt = orderLog.currentPrice * orderLog.sales
                val shopId = orderLog.shopId.toString
                jedis.hincrByFloat(Constants.KEY_SHOP_AMT_RANK, shopId, amt)
            })
            JedisUtil.release(jedis)
        })
    }
    //实时总交易额
    def calcTotalAmt(standardRDD:RDD[OrderLog]): Unit = {
        standardRDD.foreachPartition(partition => {
            val jedis = JedisUtil.getJedis
            var currentTotalAmt = 0.0
            partition.foreach(orderLog => {
                val price = orderLog.currentPrice
                val sales = orderLog.sales
                currentTotalAmt += price * sales
            })
            jedis.incrByFloat(Constants.KEY_TOTAL_AMT, currentTotalAmt)
            JedisUtil.release(jedis)
        })
    }

    def createMsg(ssc: StreamingContext, topics:Iterable[String], kafkaParams:Map[String, Object]): InputDStream[ConsumerRecord[String, String]] = {
        val offsets: Map[TopicPartition, Long] = getFromOffsets(topics)
        var message:InputDStream[ConsumerRecord[String, String]] = null
        if(offsets.isEmpty) { //从开始读取
            message = KafkaUtils.createDirectStream[String, String](ssc,
                LocationStrategies.PreferConsistent, //本地化策略（executor和kafka broker(partition)之间对应关系）
                ConsumerStrategies.Subscribe[String, String](topics, kafkaParams))
        } else {//基于偏移量
            message = KafkaUtils.createDirectStream[String, String](ssc,
                LocationStrategies.PreferConsistent, //本地化策略（executor和kafka broker(partition)之间对应关系）
                ConsumerStrategies.Subscribe[String, String](topics, kafkaParams, offsets))
        }
       message
    }
    //获取偏移量信息
    def getFromOffsets(topics:Iterable[String]): Map[TopicPartition, Long] = {
        val jedis = JedisUtil.getJedis
        val offsets = mutable.Map[TopicPartition, Long]()
        for(topic <- topics) {
            val gpMap = jedis.hgetAll(topic)
            for((gp, offsetStr) <- gpMap) {
                val partition = gp.substring(gp.indexOf("|") + 1).toInt
                val offset = offsetStr.toLong
                offsets.put(new TopicPartition(topic, partition), offset)
            }
        }
        JedisUtil.release(jedis)
        offsets.toMap
    }

    def storeOffsets(offsetRanges:Array[OffsetRange], group:String): Unit = {
        val jedis = JedisUtil.getJedis
        for(offsetRange <- offsetRanges) {
            val topic = offsetRange.topic
            val partition = offsetRange.partition
            val offset = offsetRange.untilOffset
            val gp = s"${group}|${partition}"
            jedis.hset(topic, gp, offset.toString)
        }
        JedisUtil.release(jedis)
    }
}
```



## 7.4.前端呈现

调试：

Springboot模块的运行方式

![img](assets\wps27.jpg) 