##创建索引库，并指定相应分词法
curl -H "Content-Type: application/json" -XPUT 'http://bigdata01:9200/chinese' 

curl -XPOST http://bigdata01:9200/chinese/fulltext/_mapping -H 'Content-Type:application/json' -d'
{
	"properties": {
		"content": {
			"type": "text",
			"analyzer": "ik_max_word",
			"search_analyzer": "ik_max_word"
		}
	}
}'


##添加数据
curl -H "Content-Type: application/json" -XPOST http://bigdata01:9200/chinese/fulltext/1 -d'{"content":"美国留给伊拉克的是个烂摊子吗"}'
curl -H "Content-Type: application/json" -XPOST http://bigdata01:9200/chinese/fulltext/2 -d'{"content":"公安部：各地校车将享最高路权"}'
curl -H "Content-Type: application/json" -XPOST http://bigdata01:9200/chinese/fulltext/3 -d'{"content":"中韩渔警冲突调查：韩警平均每天扣1艘中国渔船"}'
curl -H "Content-Type: application/json" -XPOST http://bigdata01:9200/chinese/fulltext/4 -d'{"content":"中国驻洛杉矶领事馆遭亚裔男子枪击 嫌犯已自首"}'
##执行查询
curl -XPOST 'http://bigdata01:9200/chinese/fulltext/_search?pretty'  -d'{
    "query" : { "match" : { "content" : "中国" }},
    "highlight" : {
        "pre_tags" : ["<font>", "<u>"],
        "post_tags" : ["</font>", "</u>"],
        "fields" : {
            "content" : {}
        }
    }
}'

添加ik和es的整合
	1、将elasticsearch-analysis-ik-master.zip下载下来进行编译
	2、将target\releases目录下面的elasticsearch-analysis-ik-6.5.0.zip上传到es中plugin目录进行解压
		在plugin再创建一个父目录保存解压之后的内容analysis-ik
	3、修改plugin-descriptor.properties中的elasticsearch.version=6.5.2和当前es的版本一致
	4、直接启动es即可
	5、当然需要同步到每一台es机器上面
	6、创建新的索引库
		指定对应列采用ik分词
		6.1°创建索引库
		curl -H "Content-Type: application/json" -XPUT 'http://bigdata01:9200/chinese' 
		6.2°对应字段设置分词
		curl -XPOST http://bigdata01:9200/chinese/fulltext/_mapping -H 'Content-Type:application/json' -d'
		{
            "_all": {"enabled": "false"},
			"properties": {
				"content": {
					"type": "text",
					"analyzer": "ik_max_word",
					"search_analyzer": "ik_max_word"
				}
			}
		}'
	7、执行termQuery查询，即可看到中文分词的效果
	
	
	
集群的部署有两种方式：
	混合部署
		某一台机器可能部署有多个进程
			NameNode
			ElasticSearch
	独立部署
		一台机器就部署一组相关的进程
			NameNode
			zkfc
			